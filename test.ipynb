{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train_data_path TRAIN_DATA_PATH]\n",
      "                             [--train_label_path TRAIN_LABEL_PATH]\n",
      "                             [--val_data_path VAL_DATA_PATH]\n",
      "                             [--val_label_path VAL_LABEL_PATH]\n",
      "                             [--color_seg COLOR_SEG] [--depth_est DEPTH_EST]\n",
      "                             [--grayscale GRAYSCALE] [--nb_epoch NB_EPOCH]\n",
      "                             [--save_path SAVE_PATH]\n",
      "                             [--loss_log_dir LOSS_LOG_DIR]\n",
      "                             [--start_path START_PATH]\n",
      "                             [--batch_size BATCH_SIZE] [--lr LR]\n",
      "                             [--model_type MODEL_TYPE] [--data_type DATA_TYPE]\n",
      "                             [--no_transform NO_TRANSFORM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"024ef310-f618-4a24-8b27-bf674c093517\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/soumyajit/.local/share/jupyter/runtime/kernel-v2-103539A4c6z2gAMqa4.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumyajit/DPT/dpt_local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import dpt.transforms as T\n",
    "from torch.optim import RMSprop, Adam\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import NYUDepth, NYUSeg\n",
    "from models import HourGlass\n",
    "from criterion import RelativeDepthLoss\n",
    "from train_utils import fit, save_checkpoint\n",
    "from torch.backends import cudnn\n",
    "from dpt.models import DPTDepthModel, DPTSegmentationModel\n",
    "from Sophia import SophiaG\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "\n",
    "def _get_aug_transform(train,grayscale = True, validation = False):\n",
    "        base_size = 256#240\n",
    "        crop_size = 200\n",
    "\n",
    "        min_size = int((0.5 if train else 1.0) * base_size)\n",
    "        max_size = int((2.0 if train else 1.0) * base_size)\n",
    "        transforms = []\n",
    "        print(\"Doing transform\")\n",
    "\n",
    "        if validation:\n",
    "            transforms.append(T.RandomResize(base_size,base_size))\n",
    "            # return T.Compose(transforms)    \n",
    "\n",
    "\n",
    "\n",
    "        if train:\n",
    "            transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "            transforms.append(T.RandomCrop(crop_size))\n",
    "            transforms.append(T.RandomResize(base_size,base_size))\n",
    "\n",
    "\n",
    "        if grayscale:\n",
    "            print(\"using grayscale\")\n",
    "            transforms.append(T.Grayscale(3))\n",
    "        transforms.append(T.ToTensor())\n",
    "        transforms.append(T.ConvertImageDtype(torch.float))\n",
    "        if grayscale:\n",
    "            transforms.append(T.Normalize(mean=[0.456, 0.456, 0.456],\n",
    "                                  std=[0.224, 0.224, 0.224]))\n",
    "        else:\n",
    "            transforms.append(T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]))\n",
    "            \n",
    "\n",
    "        return T.Compose(transforms)\n",
    "\n",
    "def main(train_data_path, train_label_path, nb_epoch, save_path, start_path=None, batch_size=4, lr=0.001, depth_est = True, color_seg = False,\n",
    "         plot_history=True,val_data_path = None, val_label_path = None, grayscale=False, model_type ='hourglass', no_transform = False, data_type='depth', loss_log_dir=None):\n",
    "        \n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if depth_est ==True and color_seg == False:\n",
    "        print(\"only depth estimation\")\n",
    "    elif depth_est == True and color_seg == True:\n",
    "        print(\"joint depth and color\")\n",
    "        #grayscale = True\n",
    "        #no_transform = False\n",
    "    elif color_seg == True:\n",
    "        print(\"only color\")\n",
    "        #grayscale = True\n",
    "        #no_transform = False\n",
    "        \n",
    "    if no_transform:\n",
    "        print(\"using no transform\")\n",
    "        trans  = T.Compose([T.ToTensor(),T.ConvertImageDtype(torch.float)])\n",
    "        if grayscale:\n",
    "                print(\"using grayscale\")\n",
    "                trans  = T.Compose([T.Grayscale(3),T.ToTensor(),T.ConvertImageDtype(torch.float)])\n",
    "    else:\n",
    "        trans = _get_aug_transform(True,grayscale)\n",
    "        \n",
    "    if data_type == 'depth':\n",
    "        train = NYUDepth(train_data_path, train_label_path, trans)\n",
    "        num_classes = 255\n",
    "        ignore_index = None\n",
    "    elif data_type == 'seg':\n",
    "        train = NYUSeg(train_data_path, train_label_path, trans, tolabel=(True, 'ade20k'))\n",
    "        num_classes = 150\n",
    "        ignore_index = 255\n",
    "    val = None\n",
    "    if val_label_path is not None:\n",
    "        if no_transform:\n",
    "            trans  = T.Compose([T.ToTensor(),T.ConvertImageDtype(torch.float)])\n",
    "        else:\n",
    "            trans = _get_aug_transform(False,grayscale,True)\n",
    "        if data_type == 'depth':\n",
    "            val = NYUDepth(val_data_path, val_label_path, trans)\n",
    "        elif data_type == 'seg':\n",
    "            val = NYUSeg(val_data_path, val_label_path, trans, tolabel=(True, 'ade20k'))\n",
    "\n",
    "    if model_type == 'hourglass':\n",
    "        model = HourGlass(depth_est, color_seg)\n",
    "        model.cuda()\n",
    "    elif model_type == 'dpt':\n",
    "        if depth_est and not color_seg:\n",
    "            model =  DPTDepthModel(\n",
    "                path=None,\n",
    "                backbone=\"vitb_rn50_384\",\n",
    "                non_negative=True,\n",
    "                enable_attention_hooks=False,\n",
    "            )\n",
    "        elif color_seg:\n",
    "            print(\"Checkpoint Seg\")\n",
    "            model = DPTSegmentationModel(\n",
    "                num_classes,\n",
    "                path=None,\n",
    "                backbone=\"vitb_rn50_384\",\n",
    "            )\n",
    "        model.cuda()\n",
    "    #optimizer = RMSprop(model.parameters(), lr, momentum=0.9)\n",
    "    #optimizer = DecoupledSophia(model.parameters(), lr=1e-3, betas=(0.9, 0.999), rho=0.04, weight_decay=1e-1,     estimator=\"Hutchinson\")\n",
    "    #optimizer = SophiaG(model.parameters(), lr=1e-5, betas=(0.965, 0.99), rho = 0.01, weight_decay=0)\n",
    "    optimizer = Adam(model.parameters(), lr)\n",
    "    #optimizer = SGD(model.parameters(), lr=2e-4, momentum=0.9)\n",
    "    #optimizer = PolynomialLR(optimizer_non_lrsch)\n",
    "\n",
    "    if start_path:\n",
    "        experiment = torch.load(start_path,torch.device('cpu'))\n",
    "        model.load_state_dict(experiment['model_state'])\n",
    "        optimizer.load_state_dict(experiment['optimizer_state'])\n",
    "        # model.to('cuda')\n",
    "\n",
    "    criterion = RelativeDepthLoss()\n",
    "    \n",
    "    # optimizer.to('cuda')\n",
    "    # history = fit(model = model, train = train, criterion= criterion, optimizer = optimizer, save_path = save_path, batch_size = batch_size,\n",
    "                #   nb_epoch = nb_epoch, depth_est = depth_est, color_seg = color_seg, validation_data = val, ignore_index = ignore_index, loss_log_dir = loss_log_dir)\n",
    "    \n",
    "    save_checkpoint(model.state_dict(), optimizer.state_dict(), save_path)\n",
    "    if plot_history:\n",
    "        # plt.plot(history['loss'], label='loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('relative depth loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    def str2bool(v):\n",
    "        if isinstance(v, bool):\n",
    "            return v\n",
    "        if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "            return True\n",
    "        elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "            return False\n",
    "        else:\n",
    "            raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_data_path', default='/home/soumyajit/ADEChallengeData2016/images/train')\n",
    "    parser.add_argument('--train_label_path', default='/home/soumyajit/ADEChallengeData2016/annotations/train')\n",
    "    parser.add_argument('--val_data_path', default='/home/soumyajit/ADEChallengeData2016/images/validation')\n",
    "    parser.add_argument('--val_label_path', default=None)\n",
    "    parser.add_argument('--color_seg',default = True,type=str2bool)\n",
    "    parser.add_argument('--depth_est',default = False,type=str2bool)\n",
    "    parser.add_argument('--grayscale',default = False,type=str2bool)\n",
    "    parser.add_argument('--nb_epoch',default = 300,type = int)\n",
    "    parser.add_argument('--save_path',default=os.path.join('/home/soumyajit/DPT/saved_models', datetime.now().strftime('%mM-%dD_%Hh-%Mm-%Ss')) + '.pth')\n",
    "    parser.add_argument('--loss_log_dir',default=None)\n",
    "    parser.add_argument('--start_path', default=None)\n",
    "    parser.add_argument('--batch_size', default=24,type  = int)\n",
    "    parser.add_argument('--lr', default=1e-5,type = float)\n",
    "    parser.add_argument('--model_type',default = 'dpt')\n",
    "    parser.add_argument('--data_type',default = 'seg')\n",
    "    parser.add_argument('--no_transform',default = False,type=str2bool)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args.train_data_path, args.train_label_path, args.nb_epoch, args.save_path, args.start_path, args.batch_size, args.lr, args.depth_est,args.color_seg,\n",
    "         False, val_data_path = args.val_data_path, val_label_path = args.val_label_path, grayscale = args.grayscale, model_type = args.model_type, no_transform = args.no_transform,\n",
    "         data_type=args.data_type, loss_log_dir = args.loss_log_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpt_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
